{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "607237b7",
   "metadata": {},
   "source": [
    "# Ubicon Tutorial\n",
    "\n",
    "This notebook demonstrates how to predict E3 ligase-substrate interactions using the Ubicon model. The tutorial walks through loading protein sequences, generating embeddings, and predicting interaction scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e885d75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from embedding import Embedding\n",
    "\n",
    "E3_fasta_path = \"examples/E3.fasta\"\n",
    "Sub_fasta_path = \"examples/Substrate.fasta\"\n",
    "\n",
    "# examples of E3 ligases (UniProtID) and their substrate (UniProtID).\n",
    "\n",
    "# FBXL5 (Q9UKA1) - IRP2 (P48200)\n",
    "# VHL (P40337) - HIF1a (Q16665)\n",
    "# RNF4 (P78317) - DDIT4 (Q9NX09)\n",
    "# βTrCP2 (Q9UKB1) - p53 (P04637)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720776e",
   "metadata": {},
   "source": [
    "## 1. Loading Protein Sequences\n",
    "\n",
    "We'll start by loading FASTA files containing protein sequences for E3 ligases and their substrates. The `fasta_to_dict` function converts these sequences into dictionaries that can be used for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed3a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "def fasta_to_dict(input_fasta):\n",
    "    \"\"\"\n",
    "    Load the specified FASTA file, create a dictionary of {ID: sequence}, \n",
    "    and save it as a .pt file.\n",
    "\n",
    "    Parameters:\n",
    "        input_fasta (str): Path to the input FASTA file.\n",
    "        output_dict (str): Path to the output dictionary file (.pt).\n",
    "    \"\"\"\n",
    "    fasta_dict = {}\n",
    "\n",
    "    for record in SeqIO.parse(input_fasta, \"fasta\"):\n",
    "        # Sequence length restriction\n",
    "        if len(record.seq) <= 2046:\n",
    "            uniprot_id = record.id.split(\"|\")[1] if \"|\" in record.id else record.id\n",
    "            fasta_dict[uniprot_id] = str(record.seq)\n",
    "\n",
    "    return fasta_dict\n",
    "\n",
    "\n",
    "E3_seq_dict = fasta_to_dict(E3_fasta_path)\n",
    "Sub_seq_dict = fasta_to_dict(Sub_fasta_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd6ff39",
   "metadata": {},
   "source": [
    "## 2. Feature Embeddings\n",
    "\n",
    "Next, we'll generate or load feature embeddings for the proteins. These embeddings capture the protein sequence information in a format suitable for machine learning models.\n",
    "\n",
    "Note: The embedding generation is commented out as it can be computationally intensive. We'll use pre-computed embeddings in this tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b430bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature embeddings using finetuned ESM C\n",
    "E3_feature_embed, Sub_feature_embed = Embedding(E3_seq_dict = E3_seq_dict,Sub_seq_dict = Sub_seq_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "691f7cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "E3_feature_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afe5ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sub_feature_embed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ca215",
   "metadata": {},
   "source": [
    "## 3. Loading Pre-computed Embeddings\n",
    "\n",
    "For this tutorial, we'll load pre-computed embeddings for:\n",
    "\n",
    "- **Sequence features (using ESM-C)**: These embeddings capture protein sequence information using a fine-tuned language model.\n",
    "\n",
    "- **Subcellular localization (using DeepLoc2)**: DeepLoc2 predicts protein subcellular localization based on sequence information. You can access DeepLoc2 through their [web server](https://services.healthtech.dtu.dk/services/DeepLoc-2.0/) or [GitHub repository](https://github.com/TviNet/DeepLoc-2.0).\n",
    "\n",
    "- **Structural information (using Foldseek)**: Foldseek generates 3Di (3D structure-based) embeddings from protein structures. The 3Di representation encodes local structural environments of each amino acid into a 1D string. To generate these embeddings:\n",
    "  - First, we obtain protein structures (e.g., from AlphaFold)\n",
    "  - Then we run Foldseek's createdb command to extract the 3Di structural alphabet\n",
    "  - This converts 3D structural information into a sequence-like representation that captures important structural features\n",
    "\n",
    "These three types of embeddings provide complementary information about the proteins that helps predict their interactions accurately. By combining sequence, structure, and localization information, Ubicon can identify potential E3-substrate pairs more effectively than using any single data type alone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3922bc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# If you cannot obtain the E3 and Sub feature embeddings, you can use the following code to obtain the embeddings.\n",
    "# If you wish to use existing embeddings, please use the code below.\n",
    "# E3_feature_embed = torch.load('examples/E3_feature_embedding.pt')\n",
    "# Sub_feature_embed = torch.load('examples/Sub_feature_embedding.pt')\n",
    "\n",
    "\n",
    "\n",
    "# Location embeddings using DeepLoc2\n",
    "# This embeddings are obtained using the DeepLoc2 model. You can see the details in the DeepLoc2 paper (https://doi.org/10.1093/nar/gkac278)  or github (https://github.com/TviNet/DeepLoc-2.0).\n",
    "\n",
    "# If you cannot obtain the E3 and Sub location embeddings, you can use the following code to obtain the embeddings.\n",
    "E3_location_embed = pd.read_csv('examples/E3_location_embedding.csv')\n",
    "Sub_location_embed = pd.read_csv('examples/Sub_location_embedding.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Structure embeddings using Foldseek\n",
    "# This embeddings are obtained using the Foldseek model. You can see the detail in the Foldseek paper (https://doi.org/10.1038/s41587-023-01773-0) or github (https://github.com/steineggerlab/foldseek)\n",
    "\n",
    "# If you cannot obtain the E3 and Sub structure embeddings, you can use the following code to obtain the embeddings\n",
    "# Loading examples/E3_structure_embed.json\n",
    "with open('examples/E3_structure_embed.json', 'r') as f:\n",
    "    E3_structure_embed = json.load(f)\n",
    "with open('examples/Sub_structure_embed.json', 'r') as f:\n",
    "    Sub_structure_embed = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7050b47b",
   "metadata": {},
   "source": [
    "## 4. Creating Protein Pairs\n",
    "\n",
    "Now we'll create a dataframe containing E3-substrate pairs for prediction. For this example, we'll use four known E3-substrate pairs from the literature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c533872",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe for E3-substrate pairs\n",
    "# Using 4 sample pairs\n",
    "pairs_data = [\n",
    "    {\"e3_uniprot_id\": \"Q9UKA1\", \"substrate_uniprot_id\": \"P48200\", \"e3_name\": \"FBXL5\", \"substrate_name\": \"IRP2\"},\n",
    "    {\"e3_uniprot_id\": \"P40337\", \"substrate_uniprot_id\": \"Q16665\", \"e3_name\": \"VHL\", \"substrate_name\": \"HIF1a\"},\n",
    "    {\"e3_uniprot_id\": \"P78317\", \"substrate_uniprot_id\": \"Q9NX09\", \"e3_name\": \"RNF4\", \"substrate_name\": \"DDIT4\"},\n",
    "    {\"e3_uniprot_id\": \"Q9UKB1\", \"substrate_uniprot_id\": \"P04637\", \"e3_name\": \"βTrCP2\", \"substrate_name\": \"p53\"}\n",
    "]\n",
    "pairs_df = pd.DataFrame(pairs_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a539edf5",
   "metadata": {},
   "source": [
    "## 5. Predicting Interaction Scores\n",
    "\n",
    "With all the embeddings loaded and pairs defined, we can now predict interaction scores using the Ubicon model. The following steps combine all embeddings and load the model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d539d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"src\")\n",
    "from score_utils import load_model, process_chunk\n",
    "\n",
    "# Path to required resources\n",
    "model_path = \"models/final_catboost_model.cbm\"  # Please change this path to the actual model path\n",
    "# Combining embedding data\n",
    "combined_embeddings = {**E3_feature_embed, **Sub_feature_embed}\n",
    "\n",
    "# Combining location information dataframes\n",
    "combined_location = pd.concat([E3_location_embed, Sub_location_embed])\n",
    "\n",
    "# Combining structure embeddings\n",
    "combined_structure = {**E3_structure_embed, **Sub_structure_embed}\n",
    "\n",
    "# Load the model\n",
    "print(\"Loading model...\")\n",
    "model = load_model(model_path)\n",
    "\n",
    "# Calculate scores\n",
    "print(\"Calculating scores for E3-substrate pairs...\")\n",
    "results_df = process_chunk(\n",
    "    pairs_df, \n",
    "    model, \n",
    "    combined_embeddings, \n",
    "    combined_location, \n",
    "    combined_structure\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800d1787",
   "metadata": {},
   "source": [
    "## 6. Score Calibration\n",
    "\n",
    "Finally, we calibrate the raw prediction scores to produce the final Ubicon scores. This calibration ensures that the scores are properly scaled and can be interpreted as confidence levels for the predicted interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8979d544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating calibration scores (Ubicon)\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "# Path to calibration model\n",
    "isotonic_model_path = \"models/isotonic_calibration_model.pkl\"  # Specify the actual model path\n",
    "\n",
    "# Loading calibration model\n",
    "try:\n",
    "    # Load Isotonic Regression model\n",
    "    ir_model = joblib.load(isotonic_model_path)\n",
    "    \n",
    "    # Calculate calibrated scores (Ubicon) from the original scores\n",
    "    scores = np.array(results_df['substrate_prediction_score'])\n",
    "    calibrated_scores = ir_model.predict(scores)\n",
    "    \n",
    "    # Add results to dataframe\n",
    "    results_df['ubicon_score'] = calibrated_scores\n",
    "    \n",
    "    # Display calibration scores (Ubicon)\n",
    "    print(\"Ubicon scores calculated successfully\")\n",
    "    display(results_df[['e3_name', 'substrate_name', 'e3_uniprot_id', 'substrate_uniprot_id', 'ubicon_score']])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Failed to load calibration model: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
